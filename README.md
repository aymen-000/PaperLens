# üî¨ ArXiv PaperLens: Intelligent Research Paper Discovery System

<div align="center">

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)

[![React](https://img.shields.io/badge/React-18.0+-61dafb.svg)](https://reactjs.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

*An AI-powered research assistant that learns your preferences and delivers personalized ArXiv paper recommendations*

[üì∫ Demo Video](/demo/demo.mkv) 
</div>

---

## üåü Overview

**ArXiv PaperLens** is a sophisticated RAG (Retrieval-Augmented Generation) system that revolutionizes how researchers discover and interact with academic papers. Using advanced machine learning techniques, it creates personalized research experiences by understanding user preferences through implicit and explicit feedback mechanisms.

### ‚ú® Key Features

- ü§ñ **Intelligent Paper Discovery**: Daily ArXiv crawling with ML-powered recommendations
- üß† **Multimodal RAG Chat**: Converse with papers using text and images via Google Gemini Pro
- üìä **Advanced User Profiling**: Dynamic embedding updates using exponential moving average algorithms
- üéØ **Personalized Recommendations**: Adaptive scoring system based on user interaction patterns
- üîç **Semantic Search**: FAISS-powered vector similarity search across 100k+ papers
- üì± **Multi-Channel Notifications**: Email digests and Telegram bot integration
- üé® **Modern UI**: Responsive React frontend with real-time interactions

## üèóÔ∏è System Architecture

```mermaid
graph TB
    subgraph "Data Layer"
        A[ArXiv API] --> B[Daily Crawler Agent]
        B --> C[PDF Processing]
        C --> D[Text & Image Extraction]
        D --> E[Vector Database<br/>FAISS Index]
    end
    
    subgraph "AI Layer"
        F[Multimodal Embedder<br/>CLIP + BGE] --> G[User Embedding Service]
        G --> H[Recommendation Engine<br/>Exponential Moving Average]
        I[Gemini Pro RAG Agent] --> J[Multimodal Q&A]
    end
    
    subgraph "Application Layer"
        K[Backend] --> L[React Frontend]
        M[LangGraph Agents] --> N[Notification Service<br/>Email + Telegram]
    end
    
    E --> I
    E --> H
    G --> K
    H --> K
    J --> L
    N --> L
```

## üßÆ Mathematical Foundation

### User Embedding Update Algorithm

The system employs an **Exponential Moving Average (EMA)** approach for updating user embeddings:

```
E_new = (1 - Œ±) √ó E_current + Œ± √ó E_weighted_papers
```

Where:
- `Œ±`: Learning rate (default: 0.1)
- `E_weighted_papers`: Weighted average of paper embeddings based on interaction types
- Interaction weights: Like(+1.0), Bookmark(+0.8), Share(+0.6), View(+0.1), Dislike(-0.5), Delete(-0.9)

### Temporal Decay Mechanism

```
E_decayed = E √ó (decay_factor^(days_since_update/30))
```

This ensures recent preferences have higher influence while preventing embedding staleness.

### Relevance Scoring

Paper relevance is computed using cosine similarity:

```
relevance = (cosine_similarity(E_user, E_paper) + 1) / 2
```

Normalized to [0,1] range for intuitive scoring.

## üöÄ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 16+ (for React frontend)
- Google API Key (Gemini Pro)
- PostgreSQL (for metadata storage)
- Docker (optional deployment)

### Installation

1. **Clone and Setup**
   ```bash
   git clone https://github.com/aymen-000/Paperlens
   cd Paperlans
   
   # Install Python dependencies
   pip install -r requirements.txt
   # or using uv (recommended)
   uv sync
   ```

2. **Environment Configuration**
   ```bash
   # Create .env file
   cat > .env << EOF
   GOOGLE_API_KEY = "your_key"
   CRAWLER_AGENT_MODEL_ID="gemini-2.5-flash"
   PROVIDER = "langchain_google_genai.ChatGoogleGenerativeAI"
   HUGGINGFACE_TOKEN_KEY = "your_token"
   JWT_SECRET_KEY = "your_key"
   ```

3. **Database Initialization**
   ```bash
   python scripts/init_db.py
   python scripts/seed_user.py
   ```

4. **Start Services**
   ```bash
   # Terminal 1: Backend API
   source .venv/bin/activate
   export PYTHONAPATH=.
   python3 backend/app/app.py
   
   # Terminal 2: Frontend (separate terminal)
   npm install 
   npm run dev
   
   ```

5. **Access Application**
   - Frontend: http://localhost:3000
   - Health Check: http://localhost:8000/health

## üõ†Ô∏è Technology Stack

### Backend
- **Flask**: High-performance async web framework
- **LangChain**: LLM orchestration and document processing
- **LangGraph**: Agent workflow management
- **FAISS**: Vector similarity search (Facebook AI)
- **PostgreSQL**: Metadata and user data storage
- **SQLAlchemy**: Database ORM

### AI/ML Components
- **Google Gemini Pro**: Multimodal language model
- **CLIP (OpenAI)**: Image-text understanding
- **BGE Embeddings**: Semantic text embeddings
- **Sentence Transformers**: Text encoding
- **PyTorch**: Deep learning framework

### Frontend
- **React**: Modern UI framework
- **Tailwind CSS**: Utility-first styling
- **Axios**: HTTP client


## üìä Project Structure

```
Paperlens/
‚îú‚îÄ‚îÄ agents/                           # ü§ñ AI Agent System
‚îÇ   ‚îú‚îÄ‚îÄ system_agents/               # Core intelligent agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crawler.py              # ArXiv paper crawler
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ papers_rag.py           # Multimodal RAG system
‚îÇ   ‚îú‚îÄ‚îÄ data/                       # Data processing & embeddings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding.py            # User embedding service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexing.py             # Vector indexing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vector_db.py            # FAISS operations
‚îÇ   ‚îú‚îÄ‚îÄ tools/                      # Agent utility tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crawler_tools.py        # PDF processing tools
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag_tools.py            # RAG helper functions
‚îÇ   ‚îú‚îÄ‚îÄ prompts/                    # LLM prompt templates
‚îÇ   ‚îî‚îÄ‚îÄ config.py                   # Agent configurations
‚îÇ
‚îú‚îÄ‚îÄ backend/                          # ‚ö° FastAPI Application
‚îÇ   ‚îî‚îÄ‚îÄ app/
‚îÇ       ‚îú‚îÄ‚îÄ models/                 # Database models
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ user.py             # User profiles
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ paper.py            # Paper metadata
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ user_embedding.py   # User preference vectors
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ user_feedback.py    # Interaction tracking
‚îÇ       ‚îú‚îÄ‚îÄ routes/                 # API endpoints
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ papers_api.py       # Paper CRUD operations
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ papers_bot.py       # RAG chat endpoints
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ user.py             # User management
‚îÇ       ‚îú‚îÄ‚îÄ services/               # Business logic
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ db_service.py       # Database operations
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ handle_interaction.py # User feedback processing
‚îÇ       ‚îî‚îÄ‚îÄ database.py             # SQLAlchemy setup
‚îÇ
‚îú‚îÄ‚îÄ frontend/                         # üé® Next.js Application
‚îÇ   ‚îú‚îÄ‚îÄ app/                        # Next.js App Router
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx                # Dashboard homepage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ login/                  # Authentication pages
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ signup/
‚îÇ   ‚îú‚îÄ‚îÄ components/                 # UI components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ paper-feed.tsx          # Paper recommendation feed
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag-panel.tsx           # Chat interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ paper-search.tsx        # Search functionality
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings-page.tsx       # User preferences
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/                     # Shadcn/UI components
‚îÇ   ‚îî‚îÄ‚îÄ lib/                        # Utilities & API clients
‚îÇ
‚îú‚îÄ‚îÄ faiss_index/                      # üîç Vector Database
‚îÇ   ‚îú‚îÄ‚îÄ text_index.faiss            # Text embeddings (BGE)
‚îÇ   ‚îú‚îÄ‚îÄ image_index.faiss           # Image embeddings (CLIP)
‚îÇ   ‚îî‚îÄ‚îÄ faiss_index/                # Legacy unified index
‚îÇ
‚îú‚îÄ‚îÄ storage/                          # üìÅ File Storage
‚îÇ   ‚îú‚îÄ‚îÄ raw/                        # Original PDF papers
‚îÇ   ‚îú‚îÄ‚îÄ processed/                  # Extracted content
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/                 # Figures & diagrams
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ paper_*/                # Per-paper text & images
‚îÇ   ‚îî‚îÄ‚îÄ papers/                     # Downloaded PDFs
‚îÇ
‚îî‚îÄ‚îÄ scripts/                          # üõ†Ô∏è Utility Scripts
    ‚îú‚îÄ‚îÄ init_db.py                  # Database initialization
    ‚îú‚îÄ‚îÄ seed_user.py                # Sample user creation
    ‚îî‚îÄ‚îÄ run_agents.py               # Agent orchestration
```

## ü§ñ Intelligent Agents

### 1. **ArXiv Crawler Agent**
- **Purpose**: Automated daily paper discovery
- **Capabilities**: 
  - Fetches 50+ papers daily based on user categories
  - PDF text extraction using PyPDF2
  - Figure/diagram extraction using PIL
  - Metadata enrichment and storage

### 2. **Multimodal RAG Agent**
- **Purpose**: Intelligent Q&A over research papers
- **Capabilities**:
  - Text-based semantic search
  - Image understanding and analysis
  - Context-aware response generation
  - Source attribution and citation

### 3. **User Learning Agent**
- **Purpose**: Preference modeling and adaptation
- **Capabilities**:
  - Real-time embedding updates
  - Interaction pattern analysis
  - Cold-start problem handling
  - Temporal preference drift detection

### 4. **Recommendation Engine**
- **Purpose**: Personalized content delivery
- **Capabilities**:
  - Multi-factor scoring algorithms
  - Diversity-aware recommendations
  - Category-based filtering
  - Performance analytics


## üîß Advanced Configuration

### Custom Categories and Weights

```python
# User category preferences with weights
CATEGORY_WEIGHTS = {
    "cs.AI": 0.2,          # Artificial Intelligence
    "cs.LG": 0.2,          # Machine Learning  
    "cs.CV": 0.2,          # Computer Vision
    "stat.ML": 0.4,        # Statistics ML
}
```

## ü§ù Contributing

We welcome contributions!

### Development Workflow
1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Make changes with tests
4. Commit with conventional commits (`feat:`, `fix:`, `docs:`)
5. Push and create Pull Request

### Areas for Contribution
- üîç New embedding models integration
- üìä Advanced analytics dashboards
- üåê Multi-language support
- ‚ö° Performance optimizations
- üé® UI/UX improvements
- üîç User feedbacks 
- üîç notification channels

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **ArXiv** for providing open access to research papers
- **Google** for Gemini Pro API access
- **Hugging Face** for transformer models and embeddings
- **Facebook AI** for FAISS vector search
- **OpenAI** for CLIP multimodal understanding

## üîÆ Future Enhancements

### üéØ Roadmap 

#### **Advanced Recommendation System**
- **üé∞ Reinforcement Learning Recommender**
  - Multi-Armed Bandit algorithms for exploration vs exploitation
  - Deep Q-Network (DQN) for long-term user engagement optimization
  - Contextual bandits considering user state, time, and reading patterns
  - A/B testing framework for recommendation strategy evaluation

#### **Enhanced User Feedback & Analytics**
- **üìä Rich Feedback Mechanisms**
  - Star ratings and detailed paper reviews
  - Reading time tracking and attention heatmaps
  - Bookmark organization with custom tags and collections
  - Social features: following researchers, sharing reading lists
  - Citation network analysis for impact-based recommendations

- **üî¨ Advanced Analytics Dashboard**
  - Personal research journey visualization
  - Topic evolution and trend analysis
  - Collaboration opportunity detection
  - Research gap identification using knowledge graphs

#### **Multi-Source Content Aggregation**
- **üåê Diversified Content Sources**
  - **LinkedIn Research Posts**: Professional insights and industry research
  - **Twitter/X Academic Threads**: Real-time research discussions and preprints
  - **Google Scholar**: Citation networks and h-index tracking
  - **Research Gate**: Social academic networking integration
  - **Medium/Towards Data Science**: Practical implementations and tutorials
  - **GitHub Research Repos**: Code implementations and reproducible research

- **üì° Social Media Intelligence**
  - Tweet sentiment analysis for trending topics
  - LinkedIn post engagement metrics
  - Research influencer identification
  - Conference hashtag monitoring (#NeurIPS2024, #ICML2024)

#### **Phase 4: AI-Powered Research Assistant**
- **ü§ñ Advanced AI Capabilities**
  - Literature gap analysis using LLMs
  - Automated research proposal generation
  - Cross-paper concept linking and knowledge graphs
  - Research methodology recommendations
  - Collaborative filtering with similar researchers

- **üîó Research Workflow Integration**
  - Zotero/Mendeley synchronization
  - LaTeX reference management
  - Notion/Obsidian knowledge base integration
  - Calendar integration for reading schedules
  - Email digest with personalized research summaries




---

## üìû Support & Contact

- üêõ **Issues**: [GitHub Issues](https://github.com/ayemn-000/Paperlens/issues)
- üí¨ **Discussions**: [GitHub Discussions](https://github.com/ayemn-000/Paperlens/discussions)
- üìß **Email**: aymne011@gmail.com

---

<div align="center">

**Built with ‚ù§Ô∏è for the research community**

*Making academic research discovery intelligent, personalized, and delightful*

[‚¨Ü Back to Top](#-arxiv-paperlens-intelligent-research-paper-discovery-system)

</div>
